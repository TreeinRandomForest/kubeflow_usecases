{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.8/site-packages (1.20.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.8/site-packages (1.17.70)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/app-root/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/app-root/lib/python3.8/site-packages (from boto3) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.70 in /opt/app-root/lib/python3.8/site-packages (from boto3) (1.20.70)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.70->boto3) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.70->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.70->boto3) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting torch\n",
      "  Downloading torch-1.8.1-cp38-cp38-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |█████████████▏                  | 330.1 MB 125.6 MB/s eta 0:00:04     |███████████                     | 277.4 MB 75.4 MB/s eta 0:00:075.6 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████        | 600.5 MB 107.9 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████▊   | 721.8 MB 128.3 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.8/site-packages (from torch) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.8.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install boto3\n",
    "!pip install torch\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import boto3\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_IMAGE = 'docker.io/pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime'\n",
    "bucket_name = 'elyra'\n",
    "S3_END_POINT = \"http://minio-kubeflow.apps.cluster-3f07.3f07.sandbox333.opentlc.com\"\n",
    "S3_ACCESS_ID = \"minio\"\n",
    "S3_ACCESS_KEY = \"minio123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'elyra',\n",
       "  'CreationDate': datetime.datetime(2021, 5, 11, 16, 21, 9, 315000, tzinfo=tzlocal())},\n",
       " {'Name': 'mlpipeline',\n",
       "  'CreationDate': datetime.datetime(2021, 5, 11, 13, 48, 5, 478000, tzinfo=tzlocal())}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_endpoint_url = 'http://minio-kubeflow.apps.cluster-3f07.3f07.sandbox333.opentlc.com'\n",
    "s3_access_key = \"minio\"\n",
    "s3_secret_key = \"minio123\"\n",
    "\n",
    "s3 = boto3.client(service_name='s3',\n",
    "              \taws_access_key_id = s3_access_key,\n",
    "              \taws_secret_access_key = s3_secret_key,\n",
    "              \tendpoint_url=s3_endpoint_url)\n",
    "\n",
    "s3.list_buckets()['Buckets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_inputs=2, n_outputs=1, n_hidden_nodes=10, n_hidden_layers=1, activation=nn.ReLU(), output_activation=None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer_list = nn.ModuleList()\n",
    "\n",
    "        for i in range(n_hidden_layers):\n",
    "            if i==0:\n",
    "                self.layer_list.append(nn.Linear(n_inputs, n_hidden_nodes))\n",
    "            else:\n",
    "                self.layer_list.append(nn.Linear(n_hidden_nodes, n_hidden_nodes))\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_hidden_nodes, n_outputs)\n",
    "\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "\n",
    "        for layer in self.layer_list:\n",
    "            out = self.activation(layer(out))\n",
    "\n",
    "        out = self.output_layer(out)\n",
    "        if self.output_activation is not None:\n",
    "            out = self.output_activation(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_store(bucket, data, key):\n",
    "    s3.put_object(Body=pickle.dumps(data),\n",
    "                      Bucket=bucket,\n",
    "                      Key=key)\n",
    "    \n",
    "def read_from_store(bucket, key):\n",
    "    raw_data = s3.get_object(Bucket=bucket,\n",
    "                                 Key=key)['Body']._raw_stream.data\n",
    "\n",
    "    return pickle.loads(raw_data)\n",
    "\n",
    "def train_model(hyperparam_idx: int, retcode_download: int, N_gridsize: int) -> int:\n",
    "    '''Look up hyperparams from store\n",
    "    and train model\n",
    "    '''\n",
    "\n",
    "    if hyperparam_idx >= N_gridsize:\n",
    "        raise ValueError(\"hyperparam_idx cannot be >= N_gridsize\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Device = {device}')\n",
    "\n",
    "\n",
    "    features_train = torch.from_numpy(read_from_store(bucket_name, 'features_train')).float()\n",
    "    target_train = torch.from_numpy(read_from_store(bucket_name, 'target_train')).float()\n",
    "    features_test = torch.from_numpy(read_from_store(bucket_name, 'features_test')).float()\n",
    "    target_test = torch.from_numpy(read_from_store(bucket_name, 'target_test')).float()\n",
    "\n",
    "    conf = read_from_store(bucket_name, 'hyperparam_grid')[hyperparam_idx]\n",
    "    lr = float(conf.get('lr', 1e-2))\n",
    "    N_epochs = int(conf.get('N_epochs', 1000))\n",
    "    num_hidden_layers = int(conf.get('num_hidden_layers', 1))\n",
    "    num_nodes = int(conf.get('num_nodes', 2))\n",
    "    activation = conf.get('activation', 'relu')\n",
    "\n",
    "    #should be dependent on vars read from config\n",
    "    if activation=='relu':\n",
    "        activation = nn.ReLU()\n",
    "    elif activation=='sigmoid':\n",
    "        activation = nn.Sigmoid()\n",
    "\n",
    "    model = Net(n_inputs=2, n_outputs=1, n_hidden_nodes=num_nodes, n_hidden_layers=num_hidden_layers, activation=activation, output_activation=nn.Sigmoid())\n",
    "    #model = nn.Sequential(nn.Linear(2, 10), nn.ReLU(), nn.Linear(10, 1), nn.Sigmoid())\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #Adam optimizer\n",
    "    model.train()    \n",
    "\n",
    "    if device!='cpu':\n",
    "        model = model.to(device)\n",
    "        features_train = features_train.to(device)\n",
    "        target_train = target_train.to(device)\n",
    "\n",
    "    for epoch in range(N_epochs): #N_epochs = number of iterations over the full dataset\n",
    "        features_shuffled = features_train\n",
    "        target_shuffled = target_train\n",
    "\n",
    "        out = model(features_shuffled) #predictions from model\n",
    "        loss = criterion(out.squeeze(), target_shuffled.squeeze()) #loss between predictions and labels\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'epoch = {epoch} loss = {loss}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #compute gradients\n",
    "        optimizer.step() #update model\n",
    "\n",
    "    out = model(features_shuffled) #predictions from model\n",
    "    train_loss = criterion(out.squeeze(), target_shuffled.squeeze()) #loss between predictions and labels\n",
    "    print(f'Train Loss : {train_loss}')\n",
    "\n",
    "    def evaluate_model(model, features_test, target_test):\n",
    "        '''Evaluate model on test set\n",
    "        and store result\n",
    "        '''\n",
    "        model.eval()\n",
    "\n",
    "        if device!='cpu':\n",
    "            features_test = features_test.to(device)\n",
    "            target_test = target_test.to(device)\n",
    "\n",
    "        out = model(features_test)\n",
    "        loss = criterion(out.squeeze(), target_test.squeeze())\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "    test_loss = evaluate_model(model, features_test, target_test)\n",
    "    print(f'Test  Loss : {test_loss}')\n",
    "\n",
    "    #write_to_store(bucket_name, {'test_loss': test_loss.item(), 'model': model}, f'score_{hyperparam_idx}', client)\n",
    "    write_to_store(bucket_name, {'test_loss': test_loss.item()}, f'score_{hyperparam_idx}')\n",
    "\n",
    "    return hyperparam_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cpu\n",
      "epoch = 0 loss = 0.8231548070907593\n",
      "Train Loss : 0.6931474208831787\n",
      "Test  Loss : 0.6931473612785339\n"
     ]
    }
   ],
   "source": [
    "retcode_download = 0\n",
    "N_gridsize = 18\n",
    "hyperparam_idx = 0 #this should be a notebook parameter\n",
    "\n",
    "retcode = train_model(hyperparam_idx, retcode_download, N_gridsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
